#!/usr/bin/env python

import argparse
import ConfigParser
import sys
import os
import os.path
import re
import argparse
import collections
import string
sys.path.append('external/pystache')
import pystache
pystache.defaults.MISSING_TAGS='strict'

# We're assuming '#' is valid to start a comment in all the configs we are amending
# which so far is true.
_MIXIN_HEADER = "# ----------------- BEGIN MIX-IN DEFINITIONS -----------------\n"
_MIXIN_FOOTER = "# ------------------ END MIX-IN DEFINITIONS ------------------\n"
_MIXIN_SOURCE = "# Source: "
_MIXIN_LINE   = "##############################################################\n"
_MIXIN_WARN   = "# Mix-In definitions are auto-generated by "

_XML_SOURCE = "<!-- Source: -->\n"
_XML_BEGIN = "<!-- "
_XML_END = " -->\n"
_XML_LINE = "<!-- ##############################################################\n -->"
_XML_WARN = "<!-- Mix-In definitions are auto-generated by -->"
_XML_HEADER = '<!-- #################### BEGIN MIX-IN DEFINITIONS #################### -->\n '
_XML_FOOTER = '<!-- #################### END MIX-IN DEFINITIONS #################### -->\n '

# These are the set of product configuration files that are modified by mixins.
# If they are named something else in the actual product directory, the mixin spec
# file should setup the mapping in the "mapping" section
_FILE_LIST = ["BoardConfig.mk", "init.rc", "init.recovery.rc", "fstab", "product.mk",
              "ueventd.rc", "AndroidBoard.mk", "gpt.ini"]

_PRODUCT_SPEC_FN = "mixins.spec"
_GROUP_SPEC_FN = "mixinfo.spec"
_OPTION_SPEC_FN = "option.spec"
_FILES_SPEC_FN = "files.spec"
_XML_SPEC_FN = "xml.spec"

abort_on_errors = True
policy_errors_found = False

append_info = []
dest_copy = []

class ReadTrackingDict(dict):
    def __init__(self, *args, **kwargs):
        super(ReadTrackingDict, self).__init__(*args, **kwargs)
        self.reads = collections.defaultdict(int)
    def __getitem__(self, key):
        self.reads[key] += 1
        return super(ReadTrackingDict, self).__getitem__(key)
    def unused_keys(self):
        return list(set(self.keys()) - set(self.reads.keys()))


def warning(s):
    sys.stderr.write(s + "\n");
    sys.stderr.flush()


def policy_error(s):
    global policy_errors_found
    sys.stderr.write("ERROR: ")
    warning(s)
    if abort_on_errors:
        global append_info
        if len(append_info) != 0:
           clean_append_info()
        sys.exit(1)
    else:
        policy_errors_found = True


def read_spec_file(specfile, cp=None):
    """read a mixin spec file and return a ConfigParser object with its
    definitions. If a ConfigParser is supplied as an argument, it will
    be augmented with the new data"""
    if not cp:
        cp = ConfigParser.SafeConfigParser()

    try:
        with open(specfile) as fp:
            cp.readfp(fp)
    except IOError:
        if os.path.islink(specfile):
            policy_error("reading specfile {} which is a symlink,"
                         " maybe it is broken".format(specfile))
        else:
            policy_error("reading specfile {}".format(specfile))

    return cp


def read_mixin_tree(basedir, mixin_tree=None):
    """return a dictionary mapping mixin groups found in a particular
    basedir with a dictionary mapping option names to the directory
    containing their configuration fragments as well as other group-level
    metadata"""

    if not mixin_tree:
        mixin_tree = {}

    groups = [i for i in os.listdir(basedir) if not i.startswith(".")]
    for group in groups:
        assert group not in mixin_tree
        mixin_tree[group] = {}
        groupdir = os.path.join(basedir, group)
        mixin_tree[group]["groupdir"] = groupdir
        mixin_tree[group]["options"] = {}
        mixin_tree[group]["deps"] = set()

        # Check for a mixinfo file in the root of the group directory
        # This is for metadata about the group as a whole. Its presence
        # is optional, many groups won't need it.
        mixinfo = os.path.join(groupdir, _GROUP_SPEC_FN)
        if os.path.exists(mixinfo):
            cp = read_spec_file(mixinfo)

            # "mixinfo.deps" is the set of groups which must be inherited
            # prior to inheriting this mixin, typically because we need the
            # other groups to define certain variables for us
            if cp.has_option("mixinfo", "deps"):
                mixin_tree[group]["deps"] = set(cp.get("mixinfo", "deps").split())

        options = [i for i in os.listdir(groupdir) if not i.startswith(".")]
        for option in options:
            assert option not in mixin_tree[group]["options"]

            mixin_tree[group]["options"][option] = {}
            cur_opt = mixin_tree[group]["options"][option]

            cur_opt["optiondir"] = os.path.join(groupdir, option)
            cur_opt["deps"] = set()
            cur_opt["defaults"] = {}

            optioninfo = os.path.join(cur_opt["optiondir"], _OPTION_SPEC_FN)
            if os.path.exists(optioninfo):
                cp = read_spec_file(optioninfo)

                # Options may define their own dependencies just like at the
                # group-level
                if cp.has_option("mixinfo", "deps"):
                    cur_opt["deps"] = set(cp.get("mixinfo", "deps").split())

                if cp.has_section("defaults"):
                    for k,v in cp.items("defaults"):
                        cur_opt["defaults"][k] = v

    return mixin_tree


def validate_selections(selections, mixin_tree, verbose=False):
    """enforce that the set of mixin selections is sane by checking
    the following:
    1) For each group selected, verify that the group exists and that
    the particular selection made within that group also exists
    2) If any groups exist for which there is no selection made, make
    the default selection for that group. If no default exists, report an
    error.
    The selections list may be altered by this function to include
    group default selections"""

    groups_seen = []
    returned_selections = []
    default_groups = []

    for (group, option, params) in selections:
        if group in groups_seen:
            policy_error("selection already made for group {}".format(group))
            continue

        groups_seen.append(group)

        if group not in mixin_tree:
            policy_error("no definition found for group {}".format(group))
            continue

        if option not in mixin_tree[group]["options"]:
            policy_error("unknown option {} for group {}".format(option, group))
            continue

        deps = mixin_tree[group]["deps"] | mixin_tree[group]["options"][option]["deps"]
        for dep in deps:
            if dep not in groups_seen:
                policy_error("group {} option {} requires that group {} be selected first".format(group, option, dep))

        defaults = mixin_tree[group]["options"][option]["defaults"]
        for k, v in defaults.iteritems():
            if k not in params:
                params[k] = v
        coerce_boolean(params)
        returned_selections.append((group, option, params))

    # The spec file may have omitted some groups. If so, pull in their
    # default options, or generate an error if there is no default
    unspecified_groups = sorted(set(mixin_tree.keys()) - set(groups_seen))
    for group in unspecified_groups:
        default_groups.append(group)
        if "default" not in mixin_tree[group]["options"]:
            if verbose:
                policy_error("group {} doesn't have a default option!".format(group))
        else:
            params = mixin_tree[group]["options"]["default"]["defaults"]
            coerce_boolean(params)
            returned_selections.append((group, "default", ReadTrackingDict(params)))

    return returned_selections


def clear_file(dest):
    """Return of list of string lines based on the destination file.
    Clear out any existing mixin defintions from the specified file; after this
    is done only the header/footer will remain. If the dest file never had anything
    in it, add the header/footer"""
    output = []
    in_mixin = False
    ever_in_mixin = False

    if os.path.exists(dest):
        with open(dest) as dfile:
            dlines = dfile.readlines()
    else:
        dlines = []

    orig_dlines = dlines[:]

    for line in dlines:
        if not in_mixin:
            output.append(line)
            if line == _MIXIN_HEADER:
                in_mixin = True
                ever_in_mixin = True
                output.append(_MIXIN_WARN + os.path.basename(sys.argv[0]) + '\n')
        else:
            if line == _MIXIN_FOOTER:
                output.append(line)
                in_mixin = False

    if in_mixin:
        # header with no footer? ok whatever
        output.append(_MIXIN_FOOTER)

    if not ever_in_mixin:
        output.append(_MIXIN_HEADER)
        output.append(_MIXIN_WARN + os.path.basename(sys.argv[0]) + '\n')
        output.append(_MIXIN_FOOTER)

    return orig_dlines, output

warn_vars = [
        "ADDITIONAL_BUILD_PROPERTIES",
        "ADDITIONAL_DEFAULT_PROPERTIES",
        "BOARD_KERNEL_CMDLINE",
        "DEVICE_PACKAGE_OVERLAYS",
        "PRODUCT_COPY_FILES",
        "PRODUCT_DEFAULT_PROPERTY_OVERRIDES",
        "PRODUCT_PACKAGES",
        "PRODUCT_PACKAGES_DEBUG",
        "PRODUCT_PACKAGES_ENG",
        "PRODUCT_PACKAGES_TESTS",
        "PRODUCT_PACKAGE_OVERLAYS",
        "PRODUCT_PROPERTY_OVERRIDES",
        ]

def amend_file(dlines, src, mixinsbase, params):
    """Augment the destination lines list with data from the source file provided.
    Assumes we have run clear_file() on dlines at some point beforehand"""
    with open(src) as sfile:
        src_contents = sfile.read()
        try:
            slines = pystache.render(src_contents, params).splitlines(True)
        except pystache.context.KeyNotFoundError as e:
            policy_error("{} depends on undefined mixin parameter '{}'".format(src, e.key))

    # sanity checks
    for line in slines:
        if mixinsbase in line:
            policy_error("build-time references to paths inside mixin directory are not allowed; {} is invalid".format(src))
        m = re.search("(\w*)\s*[:][=]", line)
        if m:
            vname = m.groups()[0]
            if vname in warn_vars:
                warning("Non-accumulative assignment to '{}' found in {}".format(vname, src))

    output = []
    for line in dlines:
        if line == _MIXIN_FOOTER:
            output.append(_MIXIN_LINE)
            output.append(_MIXIN_SOURCE + src + "\n")
            output.append(_MIXIN_LINE)
            output.extend(slines)
        output.append(line)

    return output

def coerce_boolean(d):
    for k in d:
        if type(d[k]) == str and d[k].lower() == 'false':
            d[k] = False

def split_params(selections):
    res = []
    for group, option_params in selections:
        m = re.match('([^\s(]+)\s*\(([^)]*)\)\s*$', option_params)
        if m is not None:
            option = m.group(1)
            params = dict(map(str.strip, x.split('=', 1)) for x in m.group(2).split(','))
            coerce_boolean(params)
            res.append((group, option, ReadTrackingDict(params)))
        else:
            res.append((group, option_params, ReadTrackingDict()))
    return res

def check_section(section, cp, specfile):
    if not cp.has_section(section):
        policy_error('specfile missing {} section: {}'.format(section, specfile))
        return False
    return True

def extrafiles_from_selections(basedir, selections):

    extrafiles = []
    for (group, option, params) in selections:
        groupdir = os.path.join(basedir, group)

        # Check for a files.spec file in the mixin directory.
        # The section [extrafiles] can be used to expand the
        # _FILE_LIST
        specfile = os.path.join(groupdir, option, _FILES_SPEC_FN)
        if os.path.isfile(specfile) or os.path.islink(specfile):
            cp = read_spec_file(specfile)
            # append all files found in the section avoiding duplicate
            # entries
            if cp.has_section("extrafiles"):
                for newfile, comment in cp.items("extrafiles"):
                    if newfile not in extrafiles + _FILE_LIST:
                        extrafiles.append(newfile)

    return extrafiles

def amend_xml_file(dest_fn,all_dest_lines,begin_templates,end_template,dry_run):
    if dry_run :
        if os.path.exists(dest_fn):
            with open(dest_fn) as dfile:
                dlines = dfile.readlines()
        else:
            dlines = []

        orig_dlines = dlines[:]
        dest_lines = []
        dest_lines.extend(begin_templates)
        dest_lines.extend(all_dest_lines)
        dest_lines.extend(end_template)

        final_orig_dlines = ''
        for orig_dline in orig_dlines:
            final_orig_dlines = final_orig_dlines + orig_dline
        final_dest_dlines = ''
        for dest_line in dest_lines:
            final_dest_dlines = final_dest_dlines + dest_line

        if final_dest_dlines != final_orig_dlines :
            warning("{} is out of date".format(dest_fn))
            return False
        else :
            return True
    else :
        with open(dest_fn,'w') as d_fn:
           d_fn.writelines(begin_templates)
           d_fn.writelines(all_dest_lines)
           d_fn.writelines(end_template)
           return True

def clear_xml_file(end_tag,dest,begin_tag=None):
    output = []

    if os.path.exists(dest):
        with open(dest) as dfile:
            dlines = dfile.readlines()
    if begin_tag is None:
        for line in dlines:
            if line.strip("\n").strip() == end_tag:
              break
            output.append(line)
    else:
        i = 0
        for line in dlines:
            i = i+1
            if  line.strip("\n").strip() == begin_tag:
                break
        for l_num in range(i,len(dlines)):
            output.append(dlines[l_num])

    return output

def read_xml_input_file(input_file):
    if os.path.exists(input_file):
        with open(input_file) as dfile:
            dlines = dfile.readlines()
    return dlines

def copy_common_file_for_xml(srcfile,dest_path,xml_path):
    params_dest = {'xml_path':xml_path}
    dest_file = dest_path+"/"+last_split_element(srcfile,"/")
    already_exist = os.path.exists(dest_file)
    with open(srcfile) as srcfile1:
        srclines = srcfile1.read()
        srclines = pystache.render(srclines, params_dest).splitlines(True)

    if dest_file not in dest_copy:
        dest_copy.append(dest_file)
        if already_exist == False:
            os.mknod(dest_file)
        with open(dest_file,"rw+") as destfile2:
            record_fix_info(dest_file,destfile2.readlines(),srclines,already_exist)
            destfile2.writelines(srclines)

def record_fix_info(dest_path,dest_f,appended_lines,already_exist):
    global append_info
    begin_line = 0
    append_lines = 0
    for line in dest_f:
        begin_line = begin_line+1

    for line in appended_lines:
        append_lines = append_lines+1
    local_append_info = {}
    local_append_info["file"] = dest_path
    local_append_info["begin_line"] = begin_line
    local_append_info["append_lines"] = append_lines
    local_append_info["already_exist"] = already_exist
    for info in append_info:
        if info["file"] == dest_path :
           return
    append_info.append(local_append_info)

def clean_append_info():
    global append_info
    global dest_copy
    for info in append_info:
        if info["already_exist"] == False:
           os.remove(info["file"])
           continue
        with open(info["file"],"r") as destfile1:
           srclines = destfile1.readlines()[0:info["begin_line"]]
        with open(info["file"],"w") as destfile2:
           destfile2.writelines(srclines)
    append_info = []
    dest_copy = []

def xml_from_selections(sf,basedir, selections):
    xml_path=sf.rstrip('/'+_PRODUCT_SPEC_FN)
    xmls = []
    common_copy = False
    for (group, option, params) in selections:
        xml = {}
        groupdir = os.path.join(basedir, group)
        specfile = os.path.join(groupdir, option, "platform.xml")
        if os.path.isfile(specfile) or os.path.islink(specfile):
            if False == common_copy:
                   copy_common_file_for_xml("device/intel/mixins/template/product.mk",os.path.join(groupdir, option),xml_path)
                   common_copy = True
            cp = read_spec_file("device/intel/mixins/template/xml.spec")
            if cp.has_section("feature"):
                for t1,t2 in cp.items("feature"):
                    if (t1 == "xml_template"):
                        if os.path.exists(t2):
                          xml["template"] = t2
                        else:
                          policy_error('template {} is not exist'.format(t2))
                    elif (t1 == "input"):
                         if os.path.exists(os.path.join(groupdir, option, t2)):
                          xml["input"]=os.path.join(groupdir, option, t2)
                         else:
                          policy_error('input xml file {} is not exist'.format(os.path.join(groupdir, option, t2)))
                    elif (t1 == "begin_insert"):
                          xml["begin_insert"] = t2
                    elif (t1 == "end_insert"):
                          xml["end_insert"] = t2
            xmls.append(xml)
    if len(xmls)>0:
        return xmls
    return None

def sort_xml_by_output(xmls):
    sorts = []

    for xml in xmls:
        sort = [xml]
        exists = False

        #if already in the sorts,exclude it
        for s1 in sorts:
            for s2 in s1:
                if last_split_element(xml["input"],"/") == last_split_element(s2["input"],"/"):
                    exists = True
                    break
        if True == exists:
            continue

        input1 = xml["input"]

        for xml2 in xmls:
            if xml2 == xml:
                continue
            if last_split_element(xml2["input"],"/") == last_split_element(input1,"/") and xml2["template"] == xml["template"]:
               sort.append(xml2)
            else:
                if last_split_element(xml2["input"],"/") == last_split_element(input1,"/") and xml2["template"] != xml["template"]:
                   policy_error('merge to the same xml, you should use the same template {}:{}'.format(xml2["input"], xml["input"]))

        sorts.append(sort)
    return sorts

def last_split_element(value,tag):
    if -1 != value.find(tag):
        return value.split(tag)[len(value.split(tag))-1]

def merge_xml(xmls,product_dir,selections,dry_run):
    sorts = sort_xml_by_output(xmls)
    retval = True
    #begin to merge all xmls,generated xml name will be the same with input name.
    for sort in sorts:
        all_dest_lines = [_XML_HEADER]
        begin_templates = []
        end_template = []
        dest_fn = ''

        for xml in sort:
            template = xml["template"]
            input_file = xml["input"]

            if os.path.exists(template):
               if '' == dest_fn :
                  dest_fn = os.path.join(product_dir, last_split_element(input_file,"/"))
               if len(begin_templates) == 0:
                  begin_templates = clear_xml_file(xml["end_insert"],template)
               if len(end_template) == 0:
                  end_template = clear_xml_file(xml["end_insert"],template,xml["begin_insert"])
               dest_lines = []
               dest_lines.append(_XML_SOURCE)
               dest_lines.append(_XML_BEGIN)
               dest_lines.append(input_file)
               dest_lines.append(_XML_END)
               dest_lines.extend(read_xml_input_file(input_file))
               all_dest_lines = all_dest_lines + dest_lines
        all_dest_lines.append(_XML_FOOTER)
        retval = amend_xml_file(dest_fn,all_dest_lines,begin_templates,end_template,dry_run)
    return retval

def handle_include(specfile):
    """ check for include section in a spec file.
    handle multiple include by recursion.
    return the list of file in the order they must be parsed."""

    cp = read_spec_file(specfile)

    if cp.has_section("include"):
        relative_path = cp.get("include","file")
        include_path = os.path.join(os.path.dirname(specfile), relative_path)
        return handle_include(include_path) + [specfile]
    return [specfile]

def process_spec_file(specfile, dry_run):

    filelist = handle_include(specfile)
    cp = None
    for f in filelist:
        cp = read_spec_file(f, cp)

    if False in (
            check_section("main", cp, specfile),
            check_section("groups", cp, specfile)
            ):
        return

    basedir = cp.get("main", "mixinsdir")
    selections = split_params(cp.items("groups"))
    mixin_tree = read_mixin_tree(basedir)
    product_dir = os.path.dirname(specfile)
    file_map = {}
    retval = True
    extrafiles = extrafiles_from_selections(basedir, selections)
    xmls = xml_from_selections(specfile,basedir, selections)

    # Set up the file map since the config files in the product directory
    # may have slightly different names than what is in _FILE_LIST
    for fname in _FILE_LIST + extrafiles:
        if cp.has_option("mapping", fname):
            file_map[fname] = cp.get("mapping", fname).split()
        else:
            file_map[fname] = [fname]

    if not dry_run:
        warning("processing {}".format(specfile))

    if xmls is not None:
        retval=merge_xml(xmls,product_dir,selections,dry_run)

    # After this, all default selections should be populated
    # and the selections should be sane
    selections = validate_selections(selections, mixin_tree, not dry_run)

    for src, dests in file_map.iteritems():
        for dest in dests:
            dest_fn = os.path.join(product_dir, dest)

            orig_dest_lines, dest_lines = clear_file(dest_fn)

            # Now check all the groups to see if they have a configuration
            # fragment to insert into the destination file
            for group, option, params in selections:
                cur_opt = mixin_tree[group]["options"][option]

                optdir = cur_opt["optiondir"]
                src_fn = os.path.join(optdir, src)

                # Any given file can have multiple fragments. We first
                # look for <frag>.1, <frag>.2, ... <frag>.9, <frag>
                # This is useful for when several mixin options have mostly
                # the same data except for maybe a few lines; you can
                # avoid copypasting a lot of stuff by using this feature
                # and symbolic links for the common bits.
                frags = [src_fn + "." + str(i) for i in range(10)]
                frags.append(src_fn)

                for frag in frags:
                    if os.path.exists(frag):
                        dest_lines = amend_file(dest_lines, frag, basedir, params)

            if dry_run:
                if cmp(dest_lines, orig_dest_lines) != 0:
                    warning("{} is out of date".format(dest_fn))
                    retval = False
            else:
                with open(dest_fn, "w") as fp:
                    fp.writelines(dest_lines)

    for group, option, params in selections:
        unused = params.unused_keys()
        if unused:
            policy_error('Unnecessary parameters {} given for mixin option'\
                         ' "{}: {}"'.format(unused, group, option))
    global append_info
    if len(append_info) != 0 :
       clean_append_info()
    return retval

def find_all_spec_files(basepath):
    """find all the mixin spec files underneath the specified
    directory (typically device/) and return a list of paths to
    them"""
    ret = []
    for root, dirs, files in os.walk(basepath):
        if "mixins.spec" in files:
            ret.append(os.path.join(root, _PRODUCT_SPEC_FN))
    return ret

def main(dry_run=False, sfiles=None, warn_only=False):
    global abort_on_errors

    ret = 0
    abort_on_errors = not warn_only
    out_of_sync = False

    if not sfiles:
        sfiles = find_all_spec_files("device/intel")

    for sf in sfiles:
        if not process_spec_file(sf, dry_run):
            out_of_sync = True

    if out_of_sync:
        warning("Board configs are out of sync with mixins, please run mixin-update")
        ret = 3

    if policy_errors_found:
        warning("Some spec files have policy issues")
        ret = 2

    return ret

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Update board configurations with mixin data based on spec file")
    parser.add_argument("-d", "--dry-run",
            help="Don't make any actual changes, exit nonzero if something needs to be updated",
            action="store_true")
    parser.add_argument("-s", "--spec",
            help="Read a specific spec file. Can be called multiple times. Defaults to scanning the tree under device/intel/ for spec files",
            action="append")
    parser.add_argument("-w", "--warn-only",
            help="Generate warnings instead of fatal errors for spec file policy violations",
            action="store_true")

    args = parser.parse_args()

    ret = main(args.dry_run, args.spec, args.warn_only)
    sys.exit(ret)
